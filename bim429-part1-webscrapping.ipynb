{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4caf2c94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T09:35:08.229358Z",
     "iopub.status.busy": "2023-12-24T09:35:08.228888Z",
     "iopub.status.idle": "2023-12-24T09:35:09.521677Z",
     "shell.execute_reply": "2023-12-24T09:35:09.519957Z"
    },
    "papermill": {
     "duration": 1.302078,
     "end_time": "2023-12-24T09:35:09.524221",
     "exception": true,
     "start_time": "2023-12-24T09:35:08.222143",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m randint\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m webdriver\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mselenium\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwebdriver\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mby\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m By\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import time\n",
    "from random import randint\n",
    "import random\n",
    "import selenium \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.common.exceptions import NoSuchElementException\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4d4a0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T07:33:01.410774Z",
     "iopub.status.busy": "2023-12-24T07:33:01.409416Z",
     "iopub.status.idle": "2023-12-24T07:33:20.528772Z",
     "shell.execute_reply": "2023-12-24T07:33:20.527443Z",
     "shell.execute_reply.started": "2023-12-24T07:33:01.410702Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87663e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T07:33:28.553266Z",
     "iopub.status.busy": "2023-12-24T07:33:28.552475Z",
     "iopub.status.idle": "2023-12-24T07:37:41.471821Z",
     "shell.execute_reply": "2023-12-24T07:37:41.470812Z",
     "shell.execute_reply.started": "2023-12-24T07:33:28.553228Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "hdr = {\"Accept-Language\": \"tr-TR,tr;q=0.5\",'User-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'}\n",
    "\n",
    "soups = []\n",
    "\n",
    "try:\n",
    "    options = webdriver.FirefoxOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument(\"--enable-javascript\") \n",
    "    driver = webdriver.Firefox(options=options)\n",
    "    driver.implicitly_wait(0.5)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    url = \"https://www.imdb.com/search/title/?title_type=tv_series&release_date=1998-01-01,&sort=moviemeter,asc&countries=TR&count=250\"\n",
    "    print(\"1\")\n",
    "    driver.get(url)\n",
    "    # Sayfanın dilini kontrol etmek için title etiketini al\n",
    "    title_element = driver.find_element(By.TAG_NAME, 'title')\n",
    "    page_language = title_element.get_attribute('lang')\n",
    "\n",
    "# Eğer sayfa dil ayarı Türkçe değilse, dil ayarlarını değiştir\n",
    "    if page_language.lower() != 'tr':\n",
    "        driver.execute_script(\"document.documentElement.lang = 'tr';\")\n",
    "    \n",
    "    print(\"2\")\n",
    "    WebDriverWait(driver, 30).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'button.ipc-btn--single-padding:nth-child(1) > svg:nth-child(2)')))\n",
    "    print(\"3\")\n",
    "\n",
    "    for _ in range(6):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        print(\"4\")\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        print(\"5\")\n",
    "        try:\n",
    "            print(\"6\")\n",
    "            more_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, 'button.ipc-btn--single-padding:nth-child(1) > svg:nth-child(2)')))\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", more_button)\n",
    "            time.sleep(5) \n",
    "            more_button.click()\n",
    "            time.sleep(30)\n",
    "            print(\"10\")\n",
    "        except NoSuchElementException as nse:\n",
    "            print(f\"Düğme bulunamadı veya tıklanamadı. Hata: {nse}\")\n",
    "\n",
    "    \n",
    "    page_source = driver.page_source\n",
    "    soups = [BeautifulSoup(page_source, \"html.parser\")]\n",
    "    print(\"11\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Hata oluştu: {e}\")\n",
    "\n",
    "finally:\n",
    "    if 'driver' in locals():\n",
    "        driver.quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7f846c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"Name\", \"Genre\", \"Date\", \"Actors\", \"AvgTime\", \"Season\", \"Episode\", \"Rating\", \"ProductionCompany\", \"Directors\", \"Writers\"])\n",
    "\n",
    "skip_count = 1000  # İlk 461 seriyi atla\n",
    "current_count = 0  # Şu anda kaçıncı seri üzerindesi\n",
    "\n",
    "for soup in soups:\n",
    "    series = soup.find_all(\"li\", {\"ipc-metadata-list-summary-item\"})\n",
    "\n",
    "    for serie in series:\n",
    "        current_count += 1\n",
    "\n",
    "        if current_count <= skip_count:\n",
    "            continue  # İlk 461 seriyi atla\n",
    "        try:\n",
    "            # Names & Links\n",
    "            header = serie.find(\"div\", {\"class\": \"ipc-title ipc-title--base ipc-title--title ipc-title-link-no-icon ipc-title--on-textPrimary sc-43986a27-9 gaoUku dli-title\"})\n",
    "            a = header.find(\"a\")\n",
    "            name = (a.text).split('.')[1]\n",
    "            link = \"https://www.imdb.com\" + a.get(\"href\")\n",
    "\n",
    "            # Genres\n",
    "            response1 = requests.get(link, headers=hdr, timeout=20)\n",
    "            response1.raise_for_status()\n",
    "            soup_detail = BeautifulSoup(response1.text, \"html.parser\")\n",
    "            genre_elements = soup_detail.find_all(\"span\", {\"class\": \"ipc-chip__text\"})\n",
    "            genres_list = [genre.text.strip() for genre in genre_elements if \"back to top\" not in genre.text.lower()]\n",
    "            genre = ', '.join(genres_list) if genres_list else None\n",
    "            \n",
    "            \n",
    "            #date\n",
    "            date_element = serie.find(\"span\", {\"sc-43986a27-8 jHYIIK dli-title-metadata-item\"})\n",
    "            date = date_element.text.strip() if date_element else None\n",
    "            \n",
    "            \n",
    "            #actors\n",
    "            actors_elements = soup_detail.find_all(\"a\", {\"sc-bfec09a1-1 gCQkeh\"})\n",
    "            actors_list = [actor.text.strip() for actor in actors_elements[:4]]\n",
    "            \n",
    "            #avgTime\n",
    "            avgtime_elements = soup_detail.find(\"ul\", {\"class\": \"ipc-inline-list ipc-inline-list--show-dividers sc-d8941411-2 cdJsTz baseAlt\"})\n",
    "            li_elements = avgtime_elements.find_all(\"li\") if avgtime_elements else None\n",
    "            avgTime = li_elements[-1].text.strip() if li_elements else Nonec\n",
    "            \n",
    "            \n",
    "            #season\n",
    "            season_elements = soup_detail.find(\"select\", {\"class\": \"ipc-simple-select__input\"})\n",
    "            opt_elements = season_elements.find_all(\"option\") if season_elements else None\n",
    "            season = opt_elements[1].text.strip() if opt_elements else 'none'\n",
    "\n",
    "            \n",
    "            \n",
    "            #rating\n",
    "            rating_elements = soup_detail.find(\"div\", {\"class\": \"sc-bde20123-2 cdQqzc\"})\n",
    "            rt_elements = rating_elements.find(\"span\") if rating_elements else None\n",
    "            rating = rt_elements.text.strip() if rt_elements else None\n",
    "            \n",
    "            \n",
    "            #episodes\n",
    "            episode_elements = soup_detail.find(\"h3\", {\"class\": \"ipc-title__text\"})\n",
    "            ep_elements = episode_elements.find(\"span\", {\"class\": \"ipc-title__subtext\"}) if episode_elements else []\n",
    "            episode = ep_elements.text.strip() if ep_elements else None\n",
    "            #print(episode)\n",
    "            \n",
    "            \n",
    "            #productionCompany\n",
    "            pc_elements = soup_detail.find(\"a\", {\"class\": \"ipc-metadata-list-item__label ipc-metadata-list-item__label--link\"}, string=lambda text: text and (\"Production company\" in text or \"Production companies\" in text))\n",
    "\n",
    "            if pc_elements:\n",
    "                ul_elements = pc_elements.find_next(\"div\", class_=\"ipc-metadata-list-item__content-container\").find(\"ul\")\n",
    "\n",
    "                if ul_elements:\n",
    "                    li_list = ul_elements.find_all(\"li\")\n",
    "                    production_company = [li.text.strip() for li in li_list]\n",
    "\n",
    "                \n",
    "                    if len(production_company) == 1:\n",
    "                        production_company = production_company[0]\n",
    "\n",
    "                    \n",
    "                    \n",
    "            \n",
    "            linkCast=soup_detail.find(\"a\",{\"class\" : \"ipc-link ipc-link--baseAlt ipc-link--inherit-color\"}, string=\"Cast & crew\")\n",
    "            if linkCast:\n",
    "                link2 = \"https://www.imdb.com\" + linkCast.get(\"href\")\n",
    "\n",
    "                try:\n",
    "                    response2 = requests.get(link2, headers=hdr, timeout=20)\n",
    "                    response2.raise_for_status()\n",
    "\n",
    "                    soup_cast = BeautifulSoup(response2.text, \"html.parser\")\n",
    "\n",
    "                    # (Geri kalan Cast & Crew işlemleri)\n",
    "\n",
    "                except requests.exceptions.RequestException as e:\n",
    "                    print(f\"Hata oluştu: {e}\")\n",
    "                    continue\n",
    "            else:\n",
    "                print(\"Uyarı: 'Cast & crew' linki bulunamadı.\")\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                response2 = requests.get(link2, headers=hdr, timeout=20)\n",
    "                response2.raise_for_status()\n",
    "\n",
    "                soup_cast = BeautifulSoup(response2.text, \"html.parser\")\n",
    "                \n",
    "                \n",
    "               #Directors\n",
    "                directors_table = soup_cast.find('table', class_='simpleCreditsTable')\n",
    "                if directors_table:\n",
    "                    \n",
    "                    director_names = [name.get_text(strip=True) for name in directors_table.select('.name a')[:2]]\n",
    "                else:\n",
    "                    None\n",
    "\n",
    "               \n",
    "                writers_tables = soup_cast.find_all('table', class_='simpleCreditsTable')\n",
    "                \n",
    "                if len(writers_tables) > 1:\n",
    "                    writer_names = [name.get_text(strip=True) for name in writers_tables[1].select('.name a')[:2]]\n",
    "                else:\n",
    "                    None\n",
    "            \n",
    "            \n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"Hata oluştu: {e}\")\n",
    "                continue\n",
    "                \n",
    "            df = pd.concat([df, pd.DataFrame({\n",
    "                \"Name\": [name],\n",
    "                \"Genre\": [genre],\n",
    "                \"Date\": [date],\n",
    "                \"Actors\": [actors_list],\n",
    "                \"AvgTime\": [avgTime],\n",
    "                \"Season\": [season],\n",
    "                \"Episode\": [episode],\n",
    "                \"Rating\": [rating],\n",
    "                \"ProductionCompany\": [production_company],\n",
    "                \"Directors\": [director_names],\n",
    "                \"Writers\": [writer_names]\n",
    "            })], ignore_index=True)\n",
    "            \n",
    "            \n",
    "            print(f\"{name} {genre} {date} {', '.join(actors_list)} {avgTime} {season} {episode} {rating} {production_company} {', '.join(director_names)} {', '.join(writer_names)}\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            time.sleep(2)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Hata oluştu: {e}\")\n",
    "            df = pd.concat([df, pd.DataFrame({\n",
    "                \"Name\": [\"yok\"],\n",
    "                \"Genre\": [\"yok\"],\n",
    "                \"Date\": [\"yok\"],\n",
    "                \"Actors\": [\"yok\"],\n",
    "                \"AvgTime\": [\"yok\"],\n",
    "                \"Season\": [\"yok\"],\n",
    "                \"Episode\": [\"yok\"],\n",
    "                \"Rating\": [\"yok\"],\n",
    "                \"ProductionCompany\": [\"yok\"],\n",
    "                \"Directors\": [\"yok\"],\n",
    "                \"Writers\": [\"yok\"]\n",
    "            })], ignore_index=True)\n",
    "            continue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872af7ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-24T09:34:03.077329Z",
     "iopub.status.busy": "2023-12-24T09:34:03.076900Z",
     "iopub.status.idle": "2023-12-24T09:34:03.104373Z",
     "shell.execute_reply": "2023-12-24T09:34:03.103169Z",
     "shell.execute_reply.started": "2023-12-24T09:34:03.077297Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"ikinci750.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6f9ce",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5.941691,
   "end_time": "2023-12-24T09:35:10.251608",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-24T09:35:04.309917",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
